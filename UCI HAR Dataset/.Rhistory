require(rJava)
library(httr)
library(httpuv)
install.packages("httpuv")
library(httr)
library(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "2db5796de04bab48004d",
secret = "3b9d2c573a93f5c09f76e2fbe0f5dbdc0ce4e884")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp, cache = False)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp, cache = FALSE)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
re2 <- content(req)
re3 <- jsonlite::fromJSON(toJSON(re2))
library(jsonlite)
re3 <- jsonlite::fromJSON(toJSON(re2))
str(re3)
names(re3)
re3$names
re3$name
names(re3)
names(re3)
re3$created_at[re3$name=="datasharing"]
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlc <- readLines(con)
close(con)
library(XML)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html <- htmlTreeParse(url,useInternalNodes = T)
html[10]
html[10,]
xpathSApply(html,"//",xmlValue)
xpathSApply(html,"/",xmlValue)
xpathSApply(html,"//title",xmlValue)
names(html)
rootNode <- xmlRoot(html)
names(rootNode)
rootNode[[10]]
rootNode[10]
rootNode[[10]][[10]]
rootNode[[1]][[10]]
htmlc <- readLines(con,10)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlc <- readLines(con,10)
close(con)
nchar(htmlc)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlc <- readLines(con,20)
close(con)
nchar(htmlc)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlc <- readLines(con,30)
close(con)
nchar(htmlc)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlc <- readLines(con,100)
close(con)
nchar(htmlc)
?readLines
?read.fwf
con2 <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
read.fwf(con2)
close(con2)
con2 <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
read.fwf(con2,widiths=c(1,2,3))
read.fwf(con2,widths=c(1,2,3))
close(con2)
con2 <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
dat <- read.fwf(con2,widths=c(4,9),header=F)
close(con2)
colnames(dat) <- c("v1","v2")
str(dat)
con2 <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
df <- read.fwf(
con2,
widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4),
skip=4
)
close(con2)
str(df)
sum(df$V4)
con2 <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
df <- read.fwf(
con2,
widths=c(12, 7, 4, 9, 4, 9, 4, 9, 4),
skip=4
)
close(con2)
str(df)
sum(df$V4)
url <- "view-source_www.momondo.com_flightredirect__s=ParavionUK&SearchId=28640d22-c60d-40a7-a396-7d6aa67b8ec4&tk=ECO&a=1&s1.o=BUH&s1.d=ATH&s1.dep=20160130&s2.o=ATH&s2.d=BUH&s2.dep=20160202&ref=result&url=http%3A%2F%2Fwww.paravion.uk.com%2Fmetabook%"
html <- htmlTreeParse(url,useInternalNodes = T)
rootNode <- xmlRoot(html)
names(rootNode)
xpathSApply(rootNode,"//title",xmlValue)
xpathSApply(rootNode,"//pageValueEUR",xmlValue)
xpathSApply(rootNode,"//name",xmlValue)
install.packages("RCurl")
library(RCurl)
library(RCurl)
require(RCurl)
require(RCurl)
install.packages("RCurl")
require(RCurl)
url.seed <- "http://www.momondo.com/login/?ReturnUrl=%2fsupplier%2fredirects.aspx"
?RCurl
getURL(url=url.seed)
html1 <- getURL(url=url.seed)
html2 <- htmlTreeParse(file=html1,useInternalNodes = T)
require(XML)
html2 <- htmlTreeParse(file=html1,useInternalNodes = T)
url.seed <- "view-source:http://www.momondo.com/flightredirect/?s=ParavionUK&SearchId=63298b06-024c-4d2e-9516-db369f464542&tk=ECO&a=1&s1.o=BUH&s1.d=ATH&s1.dep=20160130&s2.o=ATH&s2.d=BUH&s2.dep=20160202&ref=result&url=http%3A%2F%2Fwww.paravion.uk.com%2Fmetabook%2F8f7d39d74a226c983fc2e4d2d1b0236d%2F15575158485%2F15575158486%3Fdeparture_date%3D2016-01-30%26return_date%3D2016-02-02%26search_id%3D94011020%26utm_source%3DMomondo_UK%26utm_medium%3Dmetasearch%26utm_campaign%3DAthens&OfferIndex=272&Count=0&FlightPosition=0&OfferPosition=0&IsFiltered=true&IsFlightPromoted=false&IsOfferPromoted=false&PapPriceEUR=107.67&TransactionId=RO0273OTP01301635ATH1810,RO0274ATH02021855OTP2030&s1.Stops=0&s2.Stops=0"
html1 <- getURL(url=url.seed)
url.seed <- "http://www.momondo.com/flightredirect/?s=ParavionUK&SearchId=63298b06-024c-4d2e-9516-db369f464542&tk=ECO&a=1&s1.o=BUH&s1.d=ATH&s1.dep=20160130&s2.o=ATH&s2.d=BUH&s2.dep=20160202&ref=result&url=http%3A%2F%2Fwww.paravion.uk.com%2Fmetabook%2F8f7d39d74a226c983fc2e4d2d1b0236d%2F15575158485%2F15575158486%3Fdeparture_date%3D2016-01-30%26return_date%3D2016-02-02%26search_id%3D94011020%26utm_source%3DMomondo_UK%26utm_medium%3Dmetasearch%26utm_campaign%3DAthens&OfferIndex=272&Count=0&FlightPosition=0&OfferPosition=0&IsFiltered=true&IsFlightPromoted=false&IsOfferPromoted=false&PapPriceEUR=107.67&TransactionId=RO0273OTP01301635ATH1810,RO0274ATH02021855OTP2030&s1.Stops=0&s2.Stops=0"
html1 <- getURL(url=url.seed)
html2 <- htmlTreeParse(file=html1,useInternalNodes = T)
rootNode <- xmlRoot(html2)
xpathSApply(rootNode,"//name",xmlValue)
names(rootNode)
xpathSApply(rootNode,"//pageValueEUR",xmlValue)
R.version.string
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf  <- read.csv(path2csv,stringsAsFactors = F)
mydf  <- read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran,ip_id,package,country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran,-time)
select(cran,-5:20)
select(cran,-(5:20))
-5:20
select(cran,-(5:20))
(-5:20)
-(5:20)
select(cran,-(5:20))
select(cran,-(X:size))
filter(cran,package=="swirl")
filter(cran,r_version=="3.1.1",country=="US")
?Comparison
filter(cran,r_version<="3.0.2",country=="IN")
filter(cran,r_version<="3.0.2",country=="IN")
filter(cran,country=="US" | country=="IN")
filter(cran,size>100500, r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,!is.na(r_version))
cran2  <- select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3 <- select(cran,ip_id,package,size)
cran3
mutate(cran3,size_mb= size / 2^20)
mutate(cran3,size_mb= size / 2^20,size_gb = size/2^10)
mutate(cran3,size_mb= size / 2^20,size_gb = size_mb/2^10)
mutate(cran3,correct_size=size+1000)
summarize(cran,avg_bytes=mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package  <- group_by(cran,package)
by_package
summarize(by_package,avg_size=mean(size))
summarize(by_package,mean(size))
submit()
pack_sum
quantile(pack_sum$count,probs=0.99)
top_counts <- filter(pack_sum,count>679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts,desc(count))
View(top_counts_sorted)
qunatile(pack_sum$unique,probs=0.99)
quantile(pack_sum$unique,probs=0.99)
top_unique <- filter(pack_sum,unique>465)
view(top_unique)
View(top_unique)
top_unique_sorted  <- arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students,sex,count,-grade)
students2
gather(students2,sex_class,count,-grade)
res <- gather(students2,sex_class,count,-grade)
res
?separate
separate(res,sex_class,c("sex","class"))
submit()
students3
submit()
submit()
?spread
submit()
extract_numeric("class5")
submit()
students4
submit()
submit()
submit()
passed
failed
passed  <- mutate(status,"passed")
passed  <- mutate(passed, status,"passed")
passed  <- mutate(passed, status="passed")
failed  <- mutate(failed, status="failed")
bind_rows(passed,failes)
bind_rows(passed,failed)
sat
?select
?separate
submit()
?group_by
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package=lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day,label=TRUE)
this_moment  <- now()
this_moment
minute(this_moment)
my_date <- ymd("1989-05-17")
my-date
my_date
class(my_date)
ymd("1989 May 17")
ymd("March 12, 1975")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment,8,34,55)
update(this_moment,hours=8,minutes=34,seconds=55)
this_moment
this_moment  <- update(this_moment,hours=17,minutes=12)
this_moment
nyc  <- now(tzone = "America/New_York")
nyc
depart  <- nyc + days(2)
depart
depart <- update(depart,hours=17,minutes=34)
depart
arrive  <- depart + hours(15) +minutes(50)
?with_tz
arrive <- with_tz(arrive,"Asia/Hong_Kong")
arrive
mdy("June 17, 2008",tz="Asia/Singapore")
mdy("June 17, 2008",tz="Singapore")
last_time <- mdy("June 17, 2008",tz="Singapore")
last_time
?new_interval
how_long <- new_interval(last_time,arrive)
as.period(how_long)
stopwatch()
library(XML)
url <- "www.momondo.com/flightredirect/?s=ParavionUK&SearchId=116e2570-2f69-4589-9a30-735d3fdb9674&tk=ECO&a=1&s1.o=BUH&s1.d=ATH&s1.dep=20160130&s2.o=ATH&s2.d=BUH&s2.dep=20160202&ref=result&url=http%3A%2F%2Fwww.paravion.uk.com%2Fmetabook%2F8f7d39d74a226c983fc2e4d2d1b0236d%2F16317203908%2F16317203909%3Fdeparture_date%3D2016-01-30%26return_date%3D2016-02-02%26search_id%3D96628902%26utm_source%3DMomondo_UK%26utm_medium%3Dmetasearch%26utm_campaign%3DAthens&OfferIndex=365&Count=0&FlightPosition=8&OfferPosition=0&IsFiltered=true&IsFlightPromoted=false&IsOfferPromoted=false&PapPriceEUR=140.07&s1.Stops=0&s2.Stops=0"
doc <- htmlTreeParse(url,useInternalNodes = T)
pageValue <- xpathSApply(doc,"//script/@pageData[1]",xmlValue)
pageValue <- xpathSApply(doc,"//script/@pageData",xmlValue)
pageValue <- xpathSApply(doc,"//script/@pageData",xmlValue)
pageValue <- xpathSApply(doc,"//script/data(@pageData)",xmlValue)
pageValue <- xpathSApply(doc,"//script/@pageData",xmlValue)
library(RCurl)
xdata <- getURL(url)
doc <- xmlParse(xdata)
pageValue <- xpathSApply(doc,"//script/@pageData",xmlValue)
xpathSApply(doc,"//script/@pageData",xmlValue)
xpathSApply(doc,"//script[1]",xmlValue)
setwd("D:/Rfiles")
if (!file.info('UCI HAR Dataset')$isdir) {
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
dir.create('UCI HAR Dataset')
download(url, dest="dataset.zip", mode="wb")
unzip("dataset.zip")
}
if (!file.info('UCI HAR Dataset')$isdir) {
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
dir.create('UCI HAR Dataset')
download(url, dest="dataset.zip", mode="wb")
unzip("dataset.zip")
}
setwd("D:/Rfiles")
if (!file.info('UCI HAR Dataset')$isdir) {
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
dir.create('UCI HAR Dataset')
download(url, dest="dataset.zip", mode="wb")
unzip("dataset.zip")
}
if (!file.info("UCI HAR Dataset")$isdir) {
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
dir.create("UCI HAR Dataset")
download(url, dest="dataset.zip", mode="wb")
unzip("./dataset.zip")
}
?file.info
?folder
?file.exists
if (!file.exists("UCI HAR Dataset")) {
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
dir.create("UCI HAR Dataset")
download(url, dest="dataset.zip", mode="wb")
unzip("./dataset.zip")
}
library(downloader)
library(dplyr)
library(tidyr)
if (!file.exists("UCI HAR Dataset")) {
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
dir.create("UCI HAR Dataset")
download(url, dest="dataset.zip", mode="wb")
unzip("./dataset.zip")
}
if (!file.exists("UCI HAR Dataset")) {
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
dir.create("UCI HAR Dataset")
setwd("D:/Rfiles/UCI HAR Dataset")
download(url, dest="dataset.zip", mode="wb")
unzip("./dataset.zip")
}
path <- getwd()
setwd("D:/Rfiles")
?unzip
path <- getwd()
download(url, dest=file.path(path,"dataset.zip"), mode="wb")
unzip(file.path(path,"dataset.zip"))
setwd(file.path(path,"UCI HAR Dataset")
setwd(file.path(path,"UCI HAR Dataset"))
getwd()
if(!file.exists("getting_cleaning_data")) {
setwd(file.path(path,"UCI HAR Dataset")) }
setwd("D:/Rfiles")
if(!file.exists("getting_cleaning_data")) {
setwd(file.path(path,"UCI HAR Dataset")) }
getwd()
if(!file.exists("UCI HAR Dataset")) {
setwd(file.path(path,"UCI HAR Dataset")) }
getwd()
if(file.exists("UCI HAR Dataset")) {
setwd(file.path(path,"UCI HAR Dataset")) }
getwd()
train_s <- read.table("./train/subject_train.txt",col.names = c("subject"))
train_x <- read.table("./train/X_train.txt")
train_y <- read.table("./train/Y_train.txt",col.names = c("y"))
?fread
features <- fread("./features.txt")
library(data.table)
features <- fread("./features.txt")
View(features)
features <- fread("./features.txt") %>% select(-1)
features <- features %>% gsub('Acc',"Acceleration",features$V2) %>%
gsub('GyroJerk',"AngularAcceleration",names(singleDataSet))
features <- features %>% gsub('Acc',"Acceleration",features$V2) %>%
gsub('GyroJerk',"AngularAcceleration",features$V2)
features <-  gsub('Acc',"Acceleration",features$V2)
features <- fread("./features.txt") %>% select(-1)
features <- gsub('Acc',"Acceleration",features$V2)
features <- gsub('GyroJerk',"AngularAcceleration",features$V2)
features <- gsub('Gyro',"AngularSpeed",features$V2)
features <- gsub('Mag',"Magnitude",features$V2)
features <- gsub('^t',"TimeDomain.",features$V2)
features <- gsub('^f',"FrequencyDomain.",features$V2)
features <- gsub('\\.mean',".Mean",features$V2)
features <- gsub('\\.std',".StandardDeviation",features$V2)
features <- gsub('Freq\\.',"Frequency.",features$V2)
features <- gsub('Freq$',"Frequency",features$V2)
features <- fread("./features.txt") %>% select(-1)
features <- features$V2
features <- gsub('Acc',"Acceleration",features)
features <- gsub('GyroJerk',"AngularAcceleration",features)
features <- gsub('Gyro',"AngularSpeed",features)
features <- gsub('Mag',"Magnitude",features)
features <- gsub('^t',"TimeDomain.",features)
features <- gsub('^f',"FrequencyDomain.",features)
features <- gsub('\\.mean',".Mean",features)
features <- gsub('\\.std',".StandardDeviation",features)
features <- gsub('Freq\\.',"Frequency.",features)
features <- gsub('Freq$',"Frequency",features)
features
colnames(train_x) <- as.vector(features)
train_data <- bind_cols(train_s,train_x,train_y)
View(train_data)
test_s <- read.table("./test/subject_train.txt",col.names = c("subject"))
test_x <- read.table("./test/X_test.txt")
test_y <- read.table("./test/Y_test.txt",col.names = c("y"))
test_s <- read.table("./test/subject_test.txt",col.names = c("subject"))
colnames(test_x) <- features
test_data <- bind_cols(test_s,test_x,test_y)
merged_data <- bind_rows(train_data,test_data)
dim(merged_data)
activity_labels <- fread("./activity_labels.txt")
View(activity_labels)
colnames(activity_labels) <- c("y","activityLabel")
View(activity_labels)
features
full_set <- bind_rows(train_data,test_data)
names(full_set)
merged_data <-  full_set  %>% merge(activity_labels,by.x="y",by.y="y") %>%
select(subject,activityLabel,contains("mean()")|contains("std()"),y)
select(subject,activityLabel,contains("mean()"),contains("std()"),y)
merged_data <-  full_set  %>% merge(activity_labels,by.x="y",by.y="y") %>%
select(subject,activityLabel,contains("mean()"),contains("std()"),y)
View(merged_data)
dim(merged_data)
merged_data <-  full_set  %>% merge(activity_labels,by.x="y",by.y="y") %>%
select(subject,activityLabel,contains("mean()"),contains("std()"),y) %>%
tbl_df %>%
print
merged_data <-  full_set  %>% merge(activity_labels,by.x="y",by.y="y") %>%
select(subject,activityLabel,contains("mean()"),contains("std()"))
averaged_data <- merged_data %>%
group_by(activityLabel,subject) %>%
summarize(mean(3:68))
averaged_data
View(averaged_data)
?summarise
averaged_data <- merged_data %>%
group_by(activityLabel,subject) %>%
summarise_each(funs(mean))
View(full_set)
dim(averaged_data)
write.table(averaged_data, file = "tidydata.txt",row.name=FALSE)
